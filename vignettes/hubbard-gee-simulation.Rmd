---
title: "CI width and coverage as a function of bootstrap replications"  
author: "Riccardo Fogliato and Shamindra Shrotriya"
output: rmarkdown::html_vignette
package: maars
bibliography: ../inst/REFERENCES.bib
resource_files:
  - figures/buja1_table1.png
vignette: >
  %\VignetteIndexEntry{CI width and coverage as a function of bootstrap replications}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

``` {r  include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  linewidth = 80,
  fig.align = "center",
  warning = FALSE,
  message = FALSE
)
```

``` {r create_chunk_options, include=FALSE}
source(here::here("R", "scripts_and_filters", "create-chunk-options.R"))
source(here::here("R", "scripts_and_filters", "wrap-lines.R"))
```

## Setup and Installation

First, we'll need to install a set of packages that will be useful for the
analysis. If you are a new user, you will need to manually run the following
commands in a new in an `R` session before running the vignette code below:

<br>
<details><summary>Required package installation and load</summary>
``` {r setup_libraries}
# Load the required packages
library(tidyverse)
library(furrr)
library(glue)
library(cli)
library(broom)
library(vroom)
library(kableExtra)
library(knitr)
```
</details>

``` {r load_maars, include = FALSE}
# This load is specific to our vignette to load the latest version
# This is not displayed to the user, since they will install maars directly
devtools::load_all()
```

## Goal of the Analysis

The standard errors that are reported by `maars` are parametrized in different
ways. For example, in the case of empirical, multiplier, residual bootstrap
standard errors a critical common parameter for these standard errors is `B`
i.e. the number of replications taken during each bootstrap resample. When
studying model misspecification, a natural question of interest then becomes:

> Given data generated by a misspecified model, what is the effect of increasing
> the number of replications i.e. `B`, on the overall standard error for any
> given model parameter, when all else is held constant?

In this analysis we intend to conduct a simulation study to understand how the
standard errors reported by empirical, multiplier, residual bootstrap vary in as
the replication parameter `B` increases. For comparison purposes it is helpful
to also report the standard errors from the well specified i.e. `lm()` output,
as well as the sandwich estimator.

Being able to investigate such questions on model misspecification in a systemic
manner, for research and pedagogical purposes are in fact a critical motivating
reason for why `maars` was developed. We break down this systematic process
slowly in the following sections.

## Step 1: Setting up the Misspecified Data generating mechanism

In order to investigate the effect of increasing the number of replication in
the bootstrap standard errors under model misspecification, we first need to
specify our misspecified data generating process. To do this we draw inspiration
from [@hubbard2010togeeornotgee]. In this paper a univariate quadratic model
was considered as a the generating process. We simplify this further and use the
following model as our true misspecified *population* data generating mechanism:

$$Y = 3 X^{2} + \epsilon, \: X \sim U[0, 10], ; \epsilon \sim
\mathcal{N}(0, \sigma^2)$$

We note that this is indeed misspecified by construction since we are only
considering fitting linear models to this quadratic data generating process.
Note that for an $n$ i.i.s. samples drawn from this population generating
mechanism, we have $Y_{i} = 3 X_{i}^{2} + \epsilon, \: X_{i} \sim U[0, 10], ; \epsilon_{i} \sim \mathcal{N}(0, \sigma^2)$ for each 
_individual i.i.d sampled observation_.

Here is a simple function for generating and fitting a single OLS well specified
linear model to this generating process:

```{r gen_ind_mod_fit}
gen_ind_mod_fit <- function(n) {
  x <- runif(n, 0, 10)
  y <- 3 * x^2 + rnorm(n, mean = 0, sd = sqrt(100))
  return(lm(y ~ x))
}
```

We can also preemptively setup the function to calculate the various confidence
intervals for a fitted `lm` model using the number of replications (`B`) and the
number of observations (`n`), as follows.

```{r get_ind_confint}
get_ind_confint <- function(covg, n, B) {
  ind_confint <- gen_ind_mod_fit(n = n) %>%
    comp_var(
      mod_fit = .,
      boot_emp = list(B = B),
      boot_sub = list(B = B, m = floor(sqrt(n))),
      boot_mul = list(B = B, weights_type = "rademacher")
    ) %>%
    get_confint(level = 0.95)
  return(ind_confint)
}
```

## Step 2: Derive Projection Parameters

For simulation purposes, we need to first compute the projection parameters for
OLS. This can be done to a high degree of accuracy, by simply fitting an OLS
linear model to our generating process with large sample size i.e. $n = 10^{7}$.
This is done as follows using our previously created helper function
(`gen_ind_mod_fit`) for the generating process.

```{r comp_proj_params}
proj_par <- gen_ind_mod_fit(1e7) %>%
  tidy() %>%
  select(term, estimate)

# Display the projection parameters summary table
proj_par %>%
  kable(x = ., format = "html", digits = 2, align = "c") %>%
  kable_styling(position = "center") %>%
  kable_classic(kable_input = .)
```

## Step 3: Setup Simulation Parameters Grid

Now to run our simulation in a _tidy_ manner we will need to setup a `tibble` of
grid parameters. This is easily done as follows:

```{r grid_params}
NUM_COVG_REPS <- 5 * 1e3 # Number of coverage replications
grid_n <- 500 # Sample size for each modeling dataset

grid_B <- c(
  seq(4, 50, by = 2),
  seq(60, 100, by = 10)
)
grid_params <- crossing(
  covg = 1:NUM_COVG_REPS,
  n = grid_n
) %>%
  crossing(B = grid_B)

# Display grid parameters
grid_params %>% 
  head() %>% 
  kable(x = ., format = "html", digits = 2, align = "c") %>%
  kable_styling(position = "center") %>%
  kable_classic(kable_input = .)
```

Here we set up a grid parameters in a single `tibble`. We take 
$B \in \{4, 6, \ldots, 50, 60, 70, \ldots, 100\}$ (our main varying parameter), 
$n = 500$ for each sampled dataset and $5000$ coverage replications  for each
simulation of grid parameter values. The final `grid_params` tibble is of length
$|B| \times 5000 = 145,000$ total individual `maars` simulated runs.

## Step 4: Run simulations over the Grid of Parameters

Now we are ready to run the simulations with a focus on getting the average
confidence interval coverage, and the average confidence width as a function of
$B$. The basic hypothesis driving the simulations is that the values of $B$
increase, we get better coverage and smaller width, but also, more importantly
that we get tighter confidence bands as the number of replications increases.

First we do the most computationally intensive step. Since our grid parameters
(i.e. `grid_params`) are in a single tibble, we can utilize the power of the
`purrr` package to map our custom confidence interval function we have
previously created. We do this by simply mapping it across each row of our grid
parameters, representing a single simulation run.

```{r confint_replications, eval=FALSE}
confint_replications <- grid_params %>%
  mutate(out_confint = future_pmap(
    .l = .,
    .f = get_ind_confint,
    .options = furrr_options(seed = TRUE),
    .progress = TRUE
  ))
```

Since our output is in a tidy tibble, we can use the power and flexibility of
data frame manipulation of say the `tidyverse` set of packages to consolidate
our results as follows:

```{r all_confint_coverage, eval=FALSE}
# Get tidy format of maars confidence interval output
all_confint <- confint_replications %>%
  unnest(out_confint) %>%
  filter(stat_type == "conf.low" | stat_type == "conf.high") %>%
  pivot_wider(names_from = stat_type, values_from = stat_val) %>%
  select(n, B, term, var_type_abb, conf.low, conf.high)

# Get confidence interval coverage
all_confint_coverage <- all_confint %>%
  inner_join(proj_par, by = "term") %>%
  mutate(ind_coverage = ifelse(conf.low <= estimate &
    conf.high >= estimate, 1, 0))
```

Now that we have our simulated data ready thanks to the convenience of the tidy
output from `maars_lm` objects, we are ready for final manipulations for
confidence interval coverage levels, and also the average confidence widths.

## Step 5: Compute Confidence Intervals and Average Confidence Width vs. Replications

We note that ideally it would be nice to compute the confidence interval
coverage and average confidence interval widths not only for empirical,
multiplier, residual bootstrap, but also for the well specified values from
`lm()` and the sandwich estimator values. Note that the latter two estimators
are not dependent on the replication parameter `B`, which is the central object
of study. So our approach is to simply split the `lm` and sandwich estimator
values and for the empirical, multiplier, residual bootstrap outputs. These can
be easily combined together afterwards into a single tibble for plotting
purposes.

First let's get the required results for `lm` and `sandwich` estimators. Note
that we take our `all_confint_coverage` and simply average over all replications
and values of `B`. Note that this is achieved by simply omitting `B` from the
`group_by` clause below.

```{r cw, eval=FALSE}
# summarise sandwich and lm
cw <- all_confint_coverage %>%
  filter(var_type_abb %in% c("sand", "lm")) %>%
  group_by(term, var_type_abb) %>%
  summarise(
    coverage = mean(ind_coverage),
    avg_width = mean(conf.high - conf.low),
    std.error.avg_width = sd(conf.high - conf.low) / sqrt(n()),
    std.error.coverage = sd(ind_coverage) / sqrt(n())
  )
```

In the case of the three bootstrap confidence interval summaries, we simply do
average over the `B` parameter, since this is critical for our analysis. The
code is identical to the previous case, except for the averaging over the `B`
parameter in the `group_by` clause:

```{r cw_x_B, eval=FALSE}
# summarise emp, mult, sub
cw_x_B <- all_confint_coverage %>%
  filter(var_type_abb %in% c("emp", "mult", "sub")) %>%
  group_by(term, B, var_type_abb) %>%
  summarise(
    coverage = mean(ind_coverage),
    avg_width = mean(conf.high - conf.low),
    std.error.avg_width = sd(conf.high - conf.low) / sqrt(n()),
    std.error.coverage = sd(ind_coverage) / sqrt(n())
  )
```

Since our results have followed a `tidy` workflow, which is naturally encouraged
by design in `maars`, we can now combine our output tibbles for `lm`/sandwich
and the empirical/residual/multiplier bootstrap confidence coverage and widths.
This is simply done as follows:

```{r cw_all, eval=FALSE}
cw_all <- cw %>%
  bind_rows(cw_x_B)
```

## Step 6: Plot Results

Now we are ready to plot the required outputs. We simply use our combined tibble
and pipe (`%>%`) into `ggplot2`. Note that since confidence interval coverage
and average confidence width as a function of `B` are fundamentally answering
two separate questions, we produce two separate plots. These are shown below.

First we plot the confidence interval coverage:

```{r confint_plt, eval=FALSE}
confint_plt <- cw_all %>%
  ggplot(aes(x = B, y = coverage, fill = var_type_abb, col = var_type_abb)) +
  geom_point() +
  geom_line() +
  geom_ribbon(aes(
    ymin = coverage - 1.96 * std.error.coverage,
    ymax = coverage + 1.96 * std.error.coverage
  ), alpha = 0.3) +
  labs(y = "Coverage") +
  theme_bw() +
  facet_wrap(~term, scales = "free") +
  geom_hline(yintercept = 0.95, linetype = "dashed")
confint_plt
```

Now using similar code, we plot the average confidence interval width as a
function of `B`. Note that `lm`/sandwich outputs are a single average value
plotted across all `B`.

``` {r avgwidth_plt, eval=FALSE}
avgwidth_plt <- cw_all %>%
  mutate(n_text = as.factor(glue("n = {n}"))) %>%
  ggplot(aes(x = B, y = avg_width, fill = var_type_abb, col = var_type_abb)) +
  geom_point() +
  geom_line() +
  geom_ribbon(aes(
    ymin = avg_width - 1.96 * std.error.avg_width,
    ymax = avg_width + 1.96 * std.error.avg_width
  ), alpha = 0.3) +
  facet_grid(~n_text) +
  labs(y = "Coverage") +
  facet_wrap(~term, scales = "free") +
  theme_bw()
avgwidth_plt
```

## Discussion

As shown above, we note that the plot reveals the following.

  - As `B` increases the empirical/residual/multiplier bootstrap confidence
    coverage converges to the specified 95% level and then stabilizes
  - In particular empirical is particularly stable at an earlier `B` value of
    TODO ADD compared to multiplier and residual bootstrap
  - It is interesting to note that residual bootstrap only works under the same
    assumptions as `lm()` i.e. observations need to be independently and
    identically distributed. This is certainly the case for this simulation, but
    empirical/multiplier bootstrap require only the weaker condition of
    independence among observations

From a practical point of view we want to emphasize that using `maars` enables
such experiments to be conducted in a *principled manner*. More specifically
using `maars` encourages a tidy workflow to systematically analyze such problems

## References
