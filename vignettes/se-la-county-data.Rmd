---
title: "Reproducing LA County Standard Errors from [@buja2019modelsasapproximationspart1]"
# author: "Riccardo Fogliato, Shamindra Shrotriya"
output: rmarkdown::html_vignette
package: maar    
bibliography: ../inst/REFERENCES.bib
vignette: >
  %\VignetteIndexEntry{Reproducing LA County Standard Errors from [@buja2019modelsasapproximationspart1]}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

``` {r  include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  linewidth = 80,
  fig.align = 'center',
  warning = FALSE,
  message = FALSE
)
```

```{r create_chunk_options, include=FALSE}
source(here::here("R", "scripts_and_filters", "create-chunk-options.R"))
source(here::here("R", "scripts_and_filters", "wrap-lines.R"))
```

## Setup and Installation

First, we'll load the `maars` package, and other `tidyverse` analysis packages.
If you are a new user, you will need to manually run the following commands in a
new in an `R` session before running the vignette code below:

``` {r install_maar, eval=FALSE}
install.packages(pkgs = c("tidyverse", "vroom", "glue", "magrittr", 
                          "knitr", "kableExtra", "remotes", "magick"))
remotes::install_github('shamindras/maar', force = TRUE)
```

We will explicitly load the `tidyverse` set of packages to get access to the
`magrittr` pipe (`%>%`) operator.

``` {r load_pkgs}
library(magrittr)
```

For all other functions we will refer to them explicitly using the
`package::function` reference method to avoid ambiguity in the source package of
the specific function used (to avoid function name conflicts).

## Goal of Analysis

We try to replicate the results of Table 1 in
[@buja2019modelsasapproximationspart1], as shown below:

``` {r table1_img, echo=FALSE, fig.cap="Table 1 from [@buja2019modelsasapproximationspart1]", out.width = '90%'}
knitr::include_graphics(here::here("vignettes", "figures", "buja1_table1.png"))
```

## Loading the data

Let's load the LA County Homeless persons data as used in
[@buja2019modelsasapproximationspart1] and briefly examine it.

``` {r load_data}
# LA County source data url, use glue to split string in easy to read format
url_la_county_dat <- glue::glue("http://www-stat.wharton.upenn.edu/~buja",
                                "STAT-961/Homeless_LA_by_Census_Tracts.csv",
                                .sep = "/")

la_county_df <- vroom::vroom(file = url_la_county_dat) # %>% dplyr::rename("MedianInc1000" = "MedianInc ($1000)")
la_county_df %>% dim(x = .)
```
The loaded dataset contains `r dim(la_county_df)[1]` observations and
`r dim(la_county_df)[2]` covariates.

Let's view the first few rows to understand the structure of the data frame.

``` {r load_data_rows}
la_county_df %>% 
  head(x = .) %>% 
  knitr::kable(x = ., format = "html", digits = 2, align = "c") %>% 
  kableExtra::kable_styling(position = "center")
```

It is already in tidy format [@wickham2014tidydata]. So we have imported the 
data correctly, given that we match the column names in Table 1 of the [@buja2019modelsasapproximationspart1] paper.

## Fitting the OLS model

We now fit an linear model of the count of homeless people (`StreetTotal`) as
the response variable, against the other covariates using Ordinary Least Squares
(OLS).

``` {r mod_fit_lm}
mod_fit <- stats::lm(formula = StreetTotal ~ ., data = la_county_df)
```

## Computing standard errors from OLS (Assuming Well Specification)

Let's first obtain the standard errors for the fitted coefficients returned from
the `lm` object. We can do this in a tidy manner using the `broom::tidy`
function applied to our fitted `lm` object, and selecting only the required
columns.

``` {r se_fit_lm}
se_lm <- broom::tidy(mod_fit) %>% 
          dplyr::select(term, std.error) %>% 
          dplyr::rename(.data = ., std.error.lm = std.error)
se_lm %>% 
  purrr::set_names(x = ., 
                   nm = c('Term', '$SE_{\\text{lin}}$')) %>% 
  knitr::kable(x = ., format = "html", digits = 2, 
               align = "c", escape = TRUE) %>% 
  kableExtra::kable_styling(position = "center")
```

```{r se_fit_lm_save_table, include=FALSE, eval=FALSE}
broom::tidy(mod_fit) %>%
  dplyr::select(term, estimate, std.error) %>%
  purrr::set_names(x = .,
                   nm = c('Term', '$\\widehat{\\beta}_{j}$',
                          '$SE_{\\text{lin}}$')) %>%
  xtable::xtable(x = ., digits = 2,
                 caption = 'Summary output from lm()') %>%
  print(include.rownames = FALSE, sanitize.text.function=function(x){x},
        file = here::here("vignettes","figures",
                          "output", "r00_mod_lm_fit.tex"))
```


## Computing standard errors from OLS using Empirical Bootstrap

We now compute the standard errors via $B = 10^{3}$ bootstrap replications of the
dataset of the same size as the original dataset i.e. of the $B$ replications
samples with replacement $n = 505$ observations from the entire data (which 
contains $n = 505$ observations).

Let's first get the OLS estimates. 
``` {r emp_fit_lm, message=FALSE, warning=FALSE}
coef_emp_boot <- maar::comp_empirical_bootstrap(mod_fit = mod_fit, B = 1000)
dplyr::glimpse(coef_emp_boot)
```

We can visualize the distribution of the variance to check whether it well 
approximates the normal distribution.

``` {r emp_qqnorm, message=FALSE, warning=FALSE}
qnorm_boot <- maar::qqnorm_bootstrap(coef_emp_boot)
qnorm_boot
```

```{r emp_qqnorm_save_image, include = F}
qnorm_boot <- maar::qqnorm_bootstrap(coef_emp_boot %>% tidyr::unnest(boot_out) %>% 
                                       dplyr::filter(term != '(Intercept)') %>%
                                       tidyr::nest(boot_out = c(term, estimate)))
qnorm_boot +
      ggplot2::theme(
    axis.text = ggplot2::element_text(size = 17),
    axis.title = ggplot2::element_text(size = 17),
    strip.text.x = ggplot2::element_text(size = 17),
    legend.text = ggplot2::element_text(size = 17),
    legend.title = ggplot2::element_text(size = 17),
    legend.position="bottom"
  ) +
  ggplot2::ggsave(filename = here::here("vignettes","figures",
                                        "output", "r_qqnorm_emp.png"), 
                  height = 6, width = 10)
```


The distribution of the OLS coefficients estimates appears to be approximately 
normal. Thanks to the fairly large sample size, we can assume to be in the asymptotic
regime. 

Let's now compute the standard errors from the outcome of the bootstrap. 
This can be done through the following function.
``` {r se_emp_fit_lm, message=FALSE, warning=FALSE}
se_emp <- maar::comp_bootstrap_summary(mod_fit = mod_fit, 
                                       boot_out = coef_emp_boot, 
                                       boot_type = 'emp') %>%
            dplyr::select(-std.error, -t.stat, -p.val)
```


This now fits, the $B =  10^{3}$ replications. let's view the output.

``` {r se_emp_fit_lm_table}
se_emp %>% 
  purrr::set_names(x = ., 
                   nm = c('Term', '$\\widehat{\\beta}_{j}$',
                          '$SE_{\\text{boot}}$', '$t_{\\text{boot}}$',
                          '$p_{\\text{boot}}$')) %>% 
  knitr::kable(x = ., format = "html", digits = 2, 
               align = "c", escape = TRUE) %>% 
  kableExtra::kable_styling(position = "center")
```

```{r se_emp_save_table, include=FALSE, eval=TRUE}
se_emp %>%
  purrr::set_names(x = ., 
                   nm = c('Term', '$\\widehat{\\beta}_{j}$',
                          '$SE_{\\text{boot}}$', '$t_{\\text{boot}}$',
                          '$p_{\\text{boot}}$')) %>% 
  xtable::xtable(x = ., digits = 2,
                 caption = 'Empirical Bootstrap Standard Errors') %>% 
  print(include.rownames = FALSE, sanitize.text.function=function(x){x},
        file = here::here("vignettes","figures",
                          "output", "r02b_se_emp.tex"))
```

As we can see, the output is in tidy format as a `tibble` object. This makes it
much more readily amenable for additional transformations using the `tidyverse`
set of packages.

Last, let's compute the confidence intervals for the 
coefficients estimated on the bootstrapped data sets via the percentile method.
```{r qqnorm}
coef_emp_boot %>% 
  maar::comp_conf_int_bootstrap(probs = c(0.025, 0.975)) %>%
  tidyr::pivot_wider(names_from = q, values_from = x)
```

## Computing standard errors from OLS using Multiplier Bootstrap

We now compute the standard errors via $B = 10^{3}$ multiplier bootstrap 
replications. This can be done through the following function.

Let's first get the OLS estimates. 
``` {r mult_fit_lm, message=FALSE, warning=FALSE}
coef_mult_boot <- maar::comp_multiplier_bootstrap_var(mod_fit = mod_fit, 
                                                      B = 1000, 
                                                      weights_type = "std_gaussian")
dplyr::glimpse(coef_mult_boot)
```

``` {r se_mult_fit_lm, message=FALSE, warning=FALSE}
# se_mult <- maar::comp_bootstrap_summary(mod_fit = mod_fit, 
#                                        boot_out = coef_mult_boot, 
#                                        boot_type = 'mult') %>%
#             dplyr::select(-std.error, -t.stat, -p.val)
```

## Computing standard errors from OLS using Sandwich Estimator

Then we obtain the standard errors using the White sandwich estimator see
[@white1980heteroskedasticconsistentcovest,
@white1980usinglsapproxunknownregfuncs].

``` {r se_sand_fit_lm}
se_sand <- maar::comp_sandwich_qr_var(mod_fit = mod_fit)
se_sand
```

```{r se_sand_save_table, include=FALSE, eval=TRUE}
se_sand %>%
  dplyr::select(-t.stat, -p.val) %>%
  purrr::set_names(x = .,
                   nm = c('Term', '$\\widehat{\\beta}_{j}$',
                          '$SE_{\\text{lin}}$', 
                          '$SE_{\\text{sand}}$', 
                          '$t_{\\text{sand}}$', '$p_{\\text{sand}}$')) %>%
  xtable::xtable(x = ., digits = 2,
                 caption = 'Sandwich Estimator Standard Errors') %>% 
  print(include.rownames = FALSE, sanitize.text.function=function(x){x},
        file = here::here("vignettes","figures",
                          "output", "r01_se_sand.tex"))
```


We can also visually compare the two types of confidence intervals.
```{r plot_std_sand}
comp_se <- se_sand %>% 
  dplyr::select(term, estimate, std.error.sand, std.error) %>%
  dplyr::filter(term != '(Intercept)') %>%
  dplyr::inner_join(se_emp %>% dplyr::select(term, std.error.boot.emp), 
                    by = 'term') %>% 
  tidyr::pivot_longer(cols = c(std.error, std.error.sand, std.error.boot.emp),
                      names_to = 'Type', 
                      values_to = 'std.error') %>%
  dplyr::mutate(Type = dplyr::case_when(
                          Type == "std.error" ~ "lm",
                          Type == "std.error.sand" ~ "sandwich",
                          Type == "std.error.boot.emp" ~ "emp.boot.")) %>%
  dplyr::mutate(Type = 
                  forcats::fct_relevel(Type, 
                                       "lm", "sandwich", "emp.boot.")) %>% 
  ggplot2::ggplot(ggplot2::aes(term, estimate, col = Type)) + 
  ggplot2::theme_bw() + 
  ggplot2::geom_point(position=ggplot2::position_dodge(width=0.5)) + 
  ggplot2::labs(x = 'Regressor', y = 'Estimate') +
  ggplot2::geom_hline(yintercept = 0, linetype = 'dashed') +
  ggplot2::geom_errorbar(ggplot2::aes(ymin = estimate - qnorm(p = 0.975, 
                                                              mean = 0, 
                                                              sd = 1)*std.error, 
                                      ymax = estimate + qnorm(p = 0.975, 
                                                              mean = 0, 
                                                              sd = 1)*std.error),
                         position = ggplot2::position_dodge(width=0.5), 
                         width = 0.1) + 
  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 30, hjust = 1)) +
  ggplot2::guides(col=ggplot2::guide_legend(title="Type of standard errors"))
comp_se
```

```{r plot_std_sand_save_image, include = FALSE}
comp_se +
  ggplot2::theme(
    #axis.text.x = ggplot2::element_blank(),
    #axis.ticks = ggplot2::element_blank(),
    axis.text.y = ggplot2::element_text(size = 20),
    axis.text.x = ggplot2::element_text(size = 13),
    axis.title = ggplot2::element_text(size = 20),
    strip.text = ggplot2::element_text(size = 20),
    legend.text = ggplot2::element_text(size = 20),
    legend.title = ggplot2::element_text(size = 20),
    legend.position="bottom"
  ) +
  ggplot2::labs(x = "Regressor", y = "OLS estimate") 
ggplot2::ggsave(
    filename = here::here(
      "vignettes", "figures",
      "output", "conf_int_comparison.png"
    ),
    height = 6, width = 10
  )
```



## Comparing standard errors

We combine the standard errors into one tibble.

``` {r se_comb}
se_comb <- se_sand %>% 
      dplyr::left_join(x = ., 
                       y = se_emp %>% dplyr::select(-estimate), 
                       by = "term")

se_comb %>%
  purrr::set_names(x = ., 
                   nm = c('Term', '$\\widehat{\\beta}_{j}$', 
                          '$SE_{\\text{lin}}$',
                          '$t_{\\text{lin}}$',
                          '$p_{\\text{lin}}$',
                          '$SE_{\\text{sand}}$', 
                          '$t_{\\text{sand}}$',
                          '$p_{\\text{sand}}$',
                          '$SE_{\\text{boot}}$',
                          '$t_{\\text{boot}}$',
                          '$p_{\\text{boot}}$')) %>% 
  knitr::kable(x = ., format = "html", digits = 2, 
               align = "c", escape = TRUE) %>% 
  kableExtra::kable_styling(position = "center")
```

```{r se_comb_save_table, include=FALSE, eval=TRUE}
se_comb %>%
  dplyr::select(-t.stat, -p.val) %>% 
  purrr::set_names(x = ., 
                   nm = c('Term', '$\\widehat{\\beta}_{j}$', 
                          '$SE_{\\text{lin}}$',
                          # '$t_{\\text{lin}}$',
                          # '$p_{\\text{lin}}$',
                          '$SE_{\\text{sand}}$', 
                          '$t_{\\text{sand}}$',
                          '$p_{\\text{sand}}$',
                          '$SE_{\\text{boot}}$',
                          '$t_{\\text{boot}}$',
                          '$p_{\\text{boot}}$')) %>% 
  xtable::xtable(x = ., digits = 2,
                 caption = 'Summary - Sandwich Estimator and Empirical Bootstrap') %>% 
  print(include.rownames = FALSE, sanitize.text.function=function(x){x},
        file = here::here("vignettes","figures",
                          "output", "r05_se_comb.tex"))
```

## Reproduce Table 1 from [@buja2019modelsasapproximationspart1]

We can also compute the ratios of the standard errors and the t-statistics 
as in Table 1 from [@buja2019modelsasapproximationspart1].

``` {r se_comb_t_stats}
# t_stats <- se_comb %>%
#             dplyr::mutate(
#               rat.boot.vs.lm = std.error.boot / std.error.lm,
#               rat.sand.vs.lm = std.error.sand / std.error.lm,
#               rat.sand.vs.boot = std.error.sand / std.error.boot,
#               t.lm = estimate / std.error.lm,
#               t.boot = estimate / std.error.boot,
#               t.sand = estimate / std.error.sand
#             )
# t_stats %>%
#   purrr::set_names(x = ., 
#                    nm = c("Term", '$\\widehat{\\beta}_{j}$', 
#                           '$SE_{\\text{lin}}$', '$SE_{\\text{boot}}$',
#                           '$SE_{\\text{sand}}$',
#                           "$\\frac{SE_{\\text{boot}}}{SE_{\\text{lin}}}$",
#                           "$\\frac{SE_{\\text{sand}}}{SE_{\\text{lin}}}$", 
#                           "$\\frac{SE_{\\text{sand}}}{SE_{\\text{boot}}}$",
#                           "$t_{\\text{lin}}$", "$t_{\\text{boot}}$", 
#                           "$t_{\\text{sand}}$")) %>%
#   knitr::kable(x = ., format = "html", digits = 2, 
#                align = "c", escape = TRUE) %>% 
#   kableExtra::kable_styling(position = "center")
```

```{r se_comb_t_stats_save_image, include=FALSE, eval=FALSE}
# t_stats %>%
#   purrr::set_names(x = .,
#                    nm = c("Term", '$\\widehat{\\beta}_{j}$',
#                           '$SE_{\\text{lin}}$', '$SE_{\\text{boot}}$',
#                           '$SE_{\\text{sand}}$',
#                           "$\\frac{SE_{\\text{boot}}}{SE_{\\text{lin}}}$",
#                           "$\\frac{SE_{\\text{sand}}}{SE_{\\text{lin}}}$",
#                           "$\\frac{SE_{\\text{sand}}}{SE_{\\text{boot}}}$",
#                           "$t_{\\text{lin}}$", "$t_{\\text{boot}}$",
#                           "$t_{\\text{sand}}$")) %>%
#   knitr::kable(x = ., format = "latex", digits = 2,
#                align = "c", escape = FALSE) %>%
#   kableExtra::kable_styling(position = "center", latex_options = "striped") %>%
#   kableExtra::as_image(x = ., width = 11,
#                        file = here::here("vignettes","figures",
#                                           "output", "r06_se_comb_t_stats.png"),
#                        density = 1000)
```


## Model diagnostics from [@buja2019modelsasapproximationspart1]

When the model is misspecified, regression coefficients should be seen as 
statistical functionals rather than fixed quantities. 
These parameters depend on the distribution of the regressors and it is
therefore important to study across the regions of the parameter space. 

Let's then first get OLS estimates under the default reweighting schema 
implemented in the `maars` package. 
```{r model_diag, eval=FALSE}
coef_rwgt <- mod_fit %>% 
  maar::comp_coef_rwgt(mod_fit = .,
                 terms_to_rwgt = names(la_county_df)[-1],
                 B = 300)
dplyr::glimpse(coef_rwgt)
```


To facilitate the interpretation of the results, we rely on graphical model 
diagnostics. Here, we show the "focal slope" model diagnostics. 
The `focal_slope` plot shows how one coefficient of interests varies 
under reweighting of each of the regressors. 
In the plot below we consider the case of "PercVacant".
```{r  model_diag_focal_slope, eval=FALSE}
fs <- maar::focal_slope(mod_fit, coef_rwgt, 'PercVacant')
fs
```

```{r model_diag_focal_slope_save_image, include = FALSE, eval=FALSE}
fs + 
    ggplot2::theme(
    axis.text = ggplot2::element_text(size = 17),
    axis.title = ggplot2::element_text(size = 17),
    strip.text.x = ggplot2::element_text(size = 17),
    legend.text = ggplot2::element_text(size = 17),
    legend.title = ggplot2::element_text(size = 17),
    legend.position="bottom"
  ) +
ggplot2::labs(x = "Grid of centers on the regressor") +
ggplot2::ggsave(filename = here::here("vignettes","figures",
                                          "output", "r_focal_slope.png"), 
              height = 6, width = 10)
```

## References
